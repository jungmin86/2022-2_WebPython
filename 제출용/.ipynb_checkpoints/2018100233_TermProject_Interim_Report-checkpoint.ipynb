{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12ef3863",
   "metadata": {},
   "source": [
    "<h1> Term Project 중간보고 </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a914dc28",
   "metadata": {},
   "source": [
    "<h2> 주제: 코로나19 전후 지역별 실내 헬스장 흥행 현황 분석 </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ca2686",
   "metadata": {},
   "source": [
    "- - -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8331b6",
   "metadata": {},
   "source": [
    "> <h3> (1) 주제 선정 이유: 왜 이 주제(분야)를 선정하게 된 이유를 나열함 </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d136c37d",
   "metadata": {},
   "source": [
    "* ``코로나19``로 인한 영업시간 제한 및 사적모임 인원 제한 때문에 실내 체육시설업 자영업자들이 힘든 시기를 보냈다. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ce6026",
   "metadata": {},
   "source": [
    "* 하지만 코로나19 관련 거리두기 정책에도 불구하고 점점 더 실내 체육의 인기는 늘어왔다고 생각한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a861465",
   "metadata": {},
   "source": [
    "* 사람들은 거리두기로 인한 스트레스를 풀 방법으로 ``혼자 할 수 있는 운동``을 찾았다. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3712554",
   "metadata": {},
   "source": [
    "* 개인적으로 느끼기에, 사람들이 코로나19 이전에는 축구, 농구 등 ``단체 종목``의 운동을 비교적 선호했던 것 같다. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963c7b46",
   "metadata": {},
   "source": [
    "* 그런데 이제 주변을 둘러보면, 단체 운동 못지 않게 헬스를 하는 사람들이 많아졌다. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2cb48fc",
   "metadata": {},
   "source": [
    "* 헬스장에 직접 가보면, 과거와 달리 ``여성 회원``들도 상당수 많이 늘어난 것처럼 보였다. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cc9016",
   "metadata": {},
   "source": [
    "* 위의 내용들은 군 전역 후인 2020년부터 계속 생각해왔던 것들이다. 하지만 어디까지나 ``생각 혹은 추측``일 뿐, 데이터에 의해 검증된 내용이 아니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0b3372",
   "metadata": {},
   "source": [
    "* 그래서 오랫동안 머릿속으로 생각만 해왔던 주제를 데이터로 검증해보고 싶어서 선정하였다. <br> 관심있는 분야에 대한 데이터 분석 경험은 앞으로의 다양한 파이썬 데이터 분석에 대한 흥미를 끌어올려줄 것이라고 생각했다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe52577",
   "metadata": {},
   "source": [
    "* 얻고자 하는 것: 누구나 말로는 할 수 있는, 또는 생각만 하던 주제를 수치로 증명함으로써 파이썬을 활용한 데이터 가공 / 분석 / 시각화 능력 향상"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e489e5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b217802",
   "metadata": {},
   "source": [
    "> <h3> (3) 인터넷을 통한 데이터 획득: 위의 명제/논리을 펼치기 위하여, 어디서 Python을 통해 어떻게 데이터를 획득했는지 구체적으로 나열함 </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5275d045",
   "metadata": {},
   "source": [
    "* 획득: ``DATA.GO.KR``(https://www.data.go.kr/data/15045048/fileData.do) 에서 ```'fulldata_10_42_01_P_체력단련장업.csv'```를 다운로드한 뒤, pandas를 활용해서 csv를 pandas의 DataFrame(df)으로 불러왔다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d5aed8",
   "metadata": {},
   "source": [
    "* pandas는 용량이 큰 파일을 읽는 데에 최적화 되어 있지 않다고 한다. 그래서 ```pd.read_csv('서울시 체력단련장업 인허가 정보.csv', chunksize = 1000, encoding='cp949')```에서 chunksize를 나누어 각각의 group 리스트로 저장한 후, pd.concat을 통해 병합해주었다. <br> <br>\n",
    "```\n",
    "group = pd.read_csv('fulldata_10_42_01_P_체력단련장업.csv', chunksize = 1000, encoding='cp949')\n",
    "group = list(group)\n",
    "df = pd.concat(group)```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d447375c",
   "metadata": {},
   "source": [
    "* 수정사항: 제안서에서는 ``경기데이터드림``과 ```서울열린데이터광장``` 에서 경기도와 서울의 헬스장 현황을 담은 csv 파일들을 다운로드 받은 뒤, 병합해서 수도권 헬스장 정보를 토대로 분석할 계획이었지만, ```DATA.GO.KR```에서 전국 헬스장을 대상으로 한 csv 파일을 얻을 수 있어서 해당 csv 파일로 데이터 분석을 진행했다. <br>웹상에서는(https://www.data.go.kr/data/15045048/fileData.do) 최근 수정일이 '2021-11-19'으로 나와있지만, csv 파일을 열어보면 '2022-10-31'까지 최신화된 것을 알 수 있었다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bdb5ff",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f5a49c",
   "metadata": {},
   "source": [
    "> <h3>(4) 분석을 위한 데이터의 가공: 데이터는 가공되지 않으면 의미가 없으므로, 어떻게 어떤 정보를 Pyhton으로 추출했는지 설명함 </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a8bf53",
   "metadata": {},
   "source": [
    "* 우선 연도별 휴업, 폐업, 취소 및 인허가 현황을 시각화하기 위해 필요한 컬럼만을(사업장명, 인허가일자, 인허가취소일자, 휴업시작일자, 휴업종료일자, 폐업일자, 영업상태명, 소재지전체주소, 도로명전체주소)을 추출해서 새로운 'df_necessary'이라는 DataFrame을 만들었다. <br>\n",
    "ex. ```df_necessary = df.loc[:,['사업장명', '인허가일자', '인허가취소일자','휴업시작일자', '휴업종료일자', '폐업일자', '영업상태명', '소재지전체주소', '도로명전체주소']]```\n",
    "* '소재지전체주소', '도로명전체주소' 컬럼에는 결측치가 존재한다. 그런데 두 컬럼 모두 결측치인 행은 존재하지 않는다. 따라서 두 컬럼의 합집합 격인 '주소' 컬럼을 생성했다. '주소' 컬럼에는 '도로명전체주소'가 결측치가 아니라면 '도로명전체주소'에 해당하는 주소를 가져오고, '도로명전체주소'가 결측치에 해당한다면 '소재지전체주소'에 해당하는 주소를 가져온다. <br>\n",
    "```df_necessary.loc[:,'주소'] = np.where(df_necessary.loc[:,'도로명전체주소'].notnull() , df_necessary['도로명전체주소'], df_necessary['소재지전체주소'])```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662f5ef8",
   "metadata": {},
   "source": [
    "* 폐업, 휴업, 취소, 말소, 만료, 정지 등의 여부를 1과 0으로 나타내는 '폐업,전출,휴업,취소,말소여부' 컬럼을 생성했다. \n",
    "* 해당하는 컬럼의 값은 각 행마다 '인허가취소일자', '폐업일자', '휴업시작일자' 컬럼 중 하나라도 결측치가 아니면 1을, 모두 결측치라면 0을 입력한다.\n",
    "* 폐업, 전출, 휴업, 취소, 말소 여부는 인허가취소일자, 휴업시작일자, 폐업일자 중 하나라도 결측치가 아니라면 해당하는 것을 알 수 있다. 세 컬럼이 모두 결측치라면, 정상적으로 영업 중인 업장에 해당한다. 즉, 여부는 0이 된다. <br>\n",
    "```df_necessary.loc[:,'폐업,전출,휴업,취소,말소여부'] = np.where(df_necessary.loc[:,'인허가취소일자'].notnull() | df_necessary.loc[:,'휴업시작일자'].notnull() | df_necessary.loc[:,'폐업일자'].notnull(), 1, 0)```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49847cc",
   "metadata": {},
   "source": [
    "* '인허가취소일자', '폐업일자', '휴업시작일자' 컬럼 중 결측치가 아닌 값이 있으면 추출하는 '폐업,전출,휴업,취소,말소일자' 컬럼을 생성했다. 만약 세 컬럼이 모두 결측치를 가지는 행이라면, '폐업,전출,휴업,취소,말소일자' 컬럼도 결측치를 가진다. <br>\n",
    "```df1.loc[:, '폐업,전출,휴업,취소,말소일자'] = df1.loc[:, ['인허가취소일자', '폐업일자', '휴업시작일자']].max(axis=1)```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8d2f1b",
   "metadata": {},
   "source": [
    "* 연도 및 월별로 지역에 따라서 신규 인허가 업장과 폐업, 휴업, 취소, 말소, 만료, 정지 등의 상태인 업장의 수를 시각화해야하기 때문에 날짜에 관련된 컬럼들로부터 연도와 월만을 추출해야 한다. \n",
    "* 우선 날짜 관련 컬럼들을 datetime으로 Dtype을 변경시켜주어야 한다. <br>\n",
    "```df1['인허가일자'] = pd.to_datetime(df1['인허가일자'], format='%Y%m%d')\n",
    "df1['인허가취소일자'] = pd.to_datetime(df1['인허가취소일자'],  format='%Y%m%d')\n",
    "df1['폐업일자'] = pd.to_datetime(df1['폐업일자'],  format='%Y%m%d')\n",
    "df1['휴업시작일자'] = pd.to_datetime(df1['휴업시작일자'],  format='%Y%m%d')\n",
    "df1['휴업종료일자'] = pd.to_datetime(df1['휴업종료일자'],  format='%Y%m%d')\n",
    "df1['폐업,전출,휴업,취소,말소일자'] = pd.to_datetime(df1['폐업,전출,휴업,취소,말소일자'],  format='%Y%m%d')```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ac5e81",
   "metadata": {},
   "source": [
    "* 이후에 날짜 관련 컬럼들에서 연도와 월만을 추출했다.\n",
    "* '폐업,전출,휴업,취소,말소연도' 컬럼에서 연도와 월을 추출한 '폐업,전출,휴업,취소,말소연월' 컬럼을 생성했다. <br>\n",
    "```df1['폐업,전출,휴업,취소,말소연월'] = df1['폐업,전출,휴업,취소,말소연도'].dt.to_period('M')```\n",
    "* 마지막으로 인허가일자의 연도와 월을 추출했다. <br>\n",
    "```df1['인허가연월'] = df1['인허가일자'].dt.to_period('M')```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f42a03",
   "metadata": {},
   "source": [
    "* <strong> 최종적으로 DataFrame은 '사업장명', '인허가일자', '인허가취소일자', '휴업시작일자', '휴업종료일자', '폐업일자', '영업상태명', '소재지전체주소', '도로명전체주소', '주소', '폐업,전출,휴업,취소,말소여부', '폐업,전출,휴업,취소,말소일자', '폐업,전출,휴업,취소,말소연월', '인허가연월'의 컬럼을 가지게 된다. <br>\n",
    "이를 바탕으로 matplotlib을 활용해서 ```시간에 따른 월별 및 지역별 추이```를 시각화할 계획이다.</strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeaf1312",
   "metadata": {},
   "source": [
    "* 앞으로의 계획: 위에 나타낸 데이터 가공 과정을 클래스(인스턴스 변수, 메소드 활용)로 만들 계획이다. <br>해당 클래스는 메소드를 통해서 특정 행정구역의 명칭을 입력하면 '주소' 컬럼을 기준으로 해당하는 지역의 실내체력단련장업 인허가 정보를 DataFrame으로 받아올 것이다. <br>또한 matplotlib을 활용해서 데이터를 시각화하는 메소드 또한 정의할 것이다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5ac885",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c738a1",
   "metadata": {},
   "source": [
    "> <h3>(7) 참고문헌: 위의 작업을 위하여 획득한 자료, 인터넷 정보, 논문, 도서 등을 나열함</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a8ebb8",
   "metadata": {},
   "source": [
    "<h4> 웹 </h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d902939f",
   "metadata": {},
   "source": [
    "* w3schools,  \"Pandas Tutorial\" (https://www.w3schools.com/python/pandas/default.asp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11260f76",
   "metadata": {},
   "source": [
    "* w3schools,  \"Numpy Tutorial\" (https://www.w3schools.com/python/numpy/default.asp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03085f96",
   "metadata": {},
   "source": [
    "* stackoverflow, \"How do I read a large csv file with pandas?\"(https://stackoverflow.com/questions/25962114/how-do-i-read-a-large-csv-file-with-pandas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f9d74c",
   "metadata": {},
   "source": [
    "* DATAQUEST, \"Tutorial: Add a Column to a Pandas DataFrame Based on an If-Else Condition\" (https://www.dataquest.io/blog/tutorial-add-column-pandas-dataframe-based-on-if-else-condition/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78430ea8",
   "metadata": {},
   "source": [
    "<h4>도서</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3e0d7b",
   "metadata": {},
   "source": [
    "* \"Do it! 점프 투 파이썬\", 박응용 지음 (ebook 활용)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645b683c",
   "metadata": {},
   "source": [
    "* \"Do it! 데이터 분석을 위한 판다스 입문\", Chen, Daniel Y. 지음, 김영하 옮김 (ebook 활용)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
